{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Train-2048.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "GZEtzMM33g0B"
      },
      "source": [
        "# 2048 Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjPTX40u3g0F"
      },
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "QBzIsJNR3g0G"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import random \n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv8vvTew3g0H"
      },
      "source": [
        "### Game Logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TJDboioE3g0H"
      },
      "source": [
        "#initialize a new game\n",
        "def new_game(n):\n",
        "    matrix = np.zeros([n,n])\n",
        "    return matrix\n",
        "\n",
        "#add 2 or 4 in the matrix\n",
        "def add_two(mat):\n",
        "    empty_cells = []\n",
        "    for i in range(len(mat)):\n",
        "        for j in range(len(mat[0])):\n",
        "            if(mat[i][j]==0):\n",
        "                empty_cells.append((i,j))\n",
        "    if(len(empty_cells)==0):\n",
        "        return mat\n",
        "    \n",
        "    index_pair = empty_cells[random.randint(0,len(empty_cells)-1)]\n",
        "    \n",
        "    prob = random.random()\n",
        "    if(prob>=0.9):\n",
        "        mat[index_pair[0]][index_pair[1]]=4\n",
        "    else:\n",
        "        mat[index_pair[0]][index_pair[1]]=2\n",
        "    return mat\n",
        "\n",
        "#to check state of the game\n",
        "def game_state(mat):\n",
        "    #if 2048 in mat:\n",
        "    #    return 'win'\n",
        "    \n",
        "    for i in range(len(mat)-1): #intentionally reduced to check the row on the right and below\n",
        "        for j in range(len(mat[0])-1): #more elegant to use exceptions but most likely this will be their solution\n",
        "            if mat[i][j]==mat[i+1][j] or mat[i][j+1]==mat[i][j]:\n",
        "                return 'not over'\n",
        "            \n",
        "    for i in range(len(mat)): #check for any zero entries\n",
        "        for j in range(len(mat[0])):\n",
        "            if mat[i][j]==0:\n",
        "                return 'not over'\n",
        "            \n",
        "    for k in range(len(mat)-1): #to check the left/right entries on the last row\n",
        "        if mat[len(mat)-1][k]==mat[len(mat)-1][k+1]:\n",
        "            return 'not over'\n",
        "        \n",
        "    for j in range(len(mat)-1): #check up/down entries on last column\n",
        "        if mat[j][len(mat)-1]==mat[j+1][len(mat)-1]:\n",
        "            return 'not over'\n",
        "        \n",
        "    return 'lose'\n",
        "\n",
        "\n",
        "def reverse(mat):\n",
        "    new=[]\n",
        "    for i in range(len(mat)):\n",
        "        new.append([])\n",
        "        for j in range(len(mat[0])):\n",
        "            new[i].append(mat[i][len(mat[0])-j-1])\n",
        "    return new\n",
        "\n",
        "def transpose(mat):\n",
        "    new=[]\n",
        "    for i in range(len(mat[0])):\n",
        "        new.append([])\n",
        "        for j in range(len(mat)):\n",
        "            new[i].append(mat[j][i])\n",
        "            \n",
        "    return np.transpose(mat)\n",
        "\n",
        "def cover_up(mat):\n",
        "    new = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
        "    done = False\n",
        "    for i in range(4):\n",
        "        count = 0\n",
        "        for j in range(4):\n",
        "            if mat[i][j]!=0:\n",
        "                new[i][count] = mat[i][j]\n",
        "                if j!=count:\n",
        "                    done=True\n",
        "                count+=1\n",
        "    return (new,done)\n",
        "\n",
        "def merge(mat):\n",
        "    done=False\n",
        "    score = 0\n",
        "    for i in range(4):\n",
        "        for j in range(3):\n",
        "            if mat[i][j]==mat[i][j+1] and mat[i][j]!=0:\n",
        "                mat[i][j]*=2\n",
        "                score += mat[i][j]   \n",
        "                mat[i][j+1]=0\n",
        "                done=True\n",
        "    return (mat,done,score)\n",
        "\n",
        "#up move\n",
        "def up(game):\n",
        "        game = transpose(game)\n",
        "        game,done = cover_up(game)\n",
        "        temp = merge(game)\n",
        "        game = temp[0]\n",
        "        done = done or temp[1]\n",
        "        game = cover_up(game)[0]\n",
        "        game = transpose(game)\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "#down move\n",
        "def down(game):\n",
        "        game=reverse(transpose(game))\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        game=transpose(reverse(game))\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "#left move\n",
        "def left(game):\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "#right move\n",
        "def right(game):\n",
        "        game=reverse(game)\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        game=reverse(game)\n",
        "        return (game,done,temp[2])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfSdjlNl3g0I"
      },
      "source": [
        "### Controls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rp--1Q6X3g0I"
      },
      "source": [
        "controls = {0:up,1:left,2:right,3:down}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDIi_fRW3g0I"
      },
      "source": [
        "### Important Functions\n",
        "* Find Empty Cell Function (Used in Reward)\n",
        "* Convert Input Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5nK7nUgY3g0I"
      },
      "source": [
        "#convert the input game matrix into corresponding power of 2 matrix.\n",
        "def change_values(X):\n",
        "    power_mat = np.zeros(shape=(1,4,4,16),dtype=np.float32)\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            if(X[i][j]==0):\n",
        "                power_mat[0][i][j][0] = 1.0\n",
        "            else:\n",
        "                power = int(math.log(X[i][j],2))\n",
        "                power_mat[0][i][j][power] = 1.0\n",
        "    return power_mat        \n",
        "\n",
        "#find the number of empty cells in the game matrix.\n",
        "def findemptyCell(mat):\n",
        "    count = 0\n",
        "    for i in range(len(mat)):\n",
        "        for j in range(len(mat)):\n",
        "            if(mat[i][j]==0):\n",
        "                count+=1\n",
        "    return count"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jhfu6-83g0J"
      },
      "source": [
        "### Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8gtkItCe3g0J"
      },
      "source": [
        "#hyper parameters\n",
        "start_learning_rate = 0.0005\n",
        "\n",
        "#gamma for Q-learning\n",
        "gamma = 0.9\n",
        "\n",
        "#epsilon greedy approach\n",
        "epsilon = 0.9\n",
        "\n",
        "#to store states and lables of the game for training\n",
        "#states of the game\n",
        "replay_memory = list()\n",
        "\n",
        "#labels of the states\n",
        "replay_labels = list()\n",
        "\n",
        "#capacity of memory\n",
        "mem_capacity = 6000"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD6vuEVh3g0J"
      },
      "source": [
        "### Network Architecture\n",
        "\n",
        "![](https://github.com/navjindervirdee/2048-deep-reinforcement-learning/blob/master/Architecture/Architecture.JPG?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3fSIbYOp3g0K"
      },
      "source": [
        "#first convolution layer depth\n",
        "depth1 = 128\n",
        "\n",
        "#second convolution layer depth\n",
        "depth2 = 128\n",
        "\n",
        "#batch size for batch gradient descent\n",
        "batch_size = 512\n",
        "\n",
        "#input units\n",
        "input_units = 16\n",
        "\n",
        "#fully connected layer neurons\n",
        "hidden_units = 256\n",
        "\n",
        "#output neurons = number of moves\n",
        "output_units = 4"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhmlN6OT3g0K"
      },
      "source": [
        "### Let's make the Tensorflow Graph\n",
        "* Loss = mean ( square( Q(st,at) - (r + gamma x max(Q(st+1,a))) ) )\n",
        "* Activation = RELU\n",
        "* Optimizer = RMSProp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgKZ6Ydv3g0K",
        "outputId": "1e08c10f-c0dd-4fa6-d3eb-0d00bf4abbc2"
      },
      "source": [
        "#input data\n",
        "tf_batch_dataset = tf.Variable(tf.zeros(shape=(batch_size, 4, 4, 16)), name='tf_batch_dataset', dtype=tf.float32)\n",
        "tf_batch_labels = tf.Variable(tf.zeros(shape=(batch_size, output_units)), name='tf_batch_labels', dtype=tf.float32)\n",
        "single_dataset = tf.Variable(tf.zeros(shape=(batch_size, 4, 4, 16)), name='single_dataset', dtype=tf.float32)\n",
        "\n",
        "#CONV LAYERS\n",
        "#conv layer1 weights\n",
        "conv1_layer1_weights = tf.Variable(tf.random.truncated_normal([1,2,input_units,depth1],mean=0,stddev=0.01))\n",
        "conv2_layer1_weights = tf.Variable(tf.random.truncated_normal([2,1,input_units,depth1],mean=0,stddev=0.01))\n",
        "\n",
        "#conv layer2 weights\n",
        "conv1_layer2_weights = tf.Variable(tf.random.truncated_normal([1,2,depth1,depth2],mean=0,stddev=0.01))\n",
        "conv2_layer2_weights = tf.Variable(tf.random.truncated_normal([2,1,depth1,depth2],mean=0,stddev=0.01))\n",
        "\n",
        "\n",
        "#FUllY CONNECTED LAYERS\n",
        "expand_size = 2*4*depth2*2 + 3*3*depth2*2 + 4*3*depth1*2\n",
        "fc_layer1_weights = tf.Variable(tf.random.truncated_normal([expand_size,hidden_units],mean=0,stddev=0.01))\n",
        "fc_layer1_biases = tf.Variable(tf.random.truncated_normal([1,hidden_units],mean=0,stddev=0.01))\n",
        "fc_layer2_weights = tf.Variable(tf.random.truncated_normal([hidden_units,output_units],mean=0,stddev=0.01))\n",
        "fc_layer2_biases = tf.Variable(tf.random.truncated_normal([1,output_units],mean=0,stddev=0.01))\n",
        "\n",
        "\n",
        "#model\n",
        "def model(dataset):\n",
        "    #layer1\n",
        "    conv1 = tf.nn.conv2d(dataset,conv1_layer1_weights,[1,1,1,1],padding='VALID') \n",
        "    conv2 = tf.nn.conv2d(dataset,conv2_layer1_weights,[1,1,1,1],padding='VALID') \n",
        "    \n",
        "    #layer1 relu activation\n",
        "    relu1 = tf.nn.relu(conv1)\n",
        "    relu2 = tf.nn.relu(conv2)\n",
        "    \n",
        "    #layer2\n",
        "    conv11 = tf.nn.conv2d(relu1,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
        "    conv12 = tf.nn.conv2d(relu1,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
        "\n",
        "    conv21 = tf.nn.conv2d(relu2,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
        "    conv22 = tf.nn.conv2d(relu2,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
        "\n",
        "    #layer2 relu activation\n",
        "    relu11 = tf.nn.relu(conv11)\n",
        "    relu12 = tf.nn.relu(conv12)\n",
        "    relu21 = tf.nn.relu(conv21)\n",
        "    relu22 = tf.nn.relu(conv22)\n",
        "    \n",
        "    #get shapes of all activations\n",
        "    shape1 = relu1.get_shape().as_list()\n",
        "    shape2 = relu2.get_shape().as_list()\n",
        "    \n",
        "    shape11 = relu11.get_shape().as_list()\n",
        "    shape12 = relu12.get_shape().as_list()\n",
        "    shape21 = relu21.get_shape().as_list()\n",
        "    shape22 = relu22.get_shape().as_list()\n",
        "\n",
        "    #expansion\n",
        "    hidden1 = tf.reshape(relu1,[shape1[0],shape1[1]*shape1[2]*shape1[3]])\n",
        "    hidden2 = tf.reshape(relu2,[shape2[0],shape2[1]*shape2[2]*shape2[3]])\n",
        "    \n",
        "    hidden11 = tf.reshape(relu11,[shape11[0],shape11[1]*shape11[2]*shape11[3]])\n",
        "    hidden12 = tf.reshape(relu12,[shape12[0],shape12[1]*shape12[2]*shape12[3]])\n",
        "    hidden21 = tf.reshape(relu21,[shape21[0],shape21[1]*shape21[2]*shape21[3]])\n",
        "    hidden22 = tf.reshape(relu22,[shape22[0],shape22[1]*shape22[2]*shape22[3]])\n",
        "\n",
        "    #concatenation\n",
        "    hidden = tf.concat([hidden1,hidden2,hidden11,hidden12,hidden21,hidden22],axis=1)\n",
        "\n",
        "    #full connected layers\n",
        "    hidden = tf.matmul(hidden,fc_layer1_weights) + fc_layer1_biases\n",
        "    hidden = tf.nn.relu(hidden)\n",
        "\n",
        "    #output layer\n",
        "    output = tf.matmul(hidden,fc_layer2_weights) + fc_layer2_biases\n",
        "    \n",
        "    #return output\n",
        "    return output\n",
        "\n",
        "#for single example\n",
        "single_output = model(single_dataset)\n",
        "\n",
        "#for batch data\n",
        "logits = model(tf_batch_dataset)\n",
        "\n",
        "\n",
        "#loss\n",
        "@tf.function\n",
        "def cost():\n",
        "  loss = tf.square(tf.subtract(tf_batch_labels,logits))\n",
        "  loss = tf.reduce_sum(loss,axis=1,keepdims=True)\n",
        "  loss = tf.reduce_mean(loss)/2.0\n",
        "  return loss\n",
        "\n",
        "#optimizer\n",
        "global_step = tf.Variable(0, name='global_step',trainable=False)  # count the number of steps taken.\n",
        "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(float(start_learning_rate), global_step, 1000, 0.90)\n",
        "#optimizer = tf.keras.optimizers.RMSprop(learning_rate).minimize(loss, var_list = global_step)\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate).minimize(cost, var_list = [])\n",
        "\n",
        "# For considered rebuilding of entire NN\n",
        "#optimizer = tf.keras.optimizers.RMSprop(learning_rate).minimize(cost, var_list = [fc_layer1_weights, fc_layer1_biases, fc_layer2_weights, fc_layer2_biases])\n",
        "#optimizer = tf.keras.optimizers.RMSprop(learning_rate).minimize(loss, var_list = global_step, tape=tf.GradientTape(persistent=False))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function cost at 0x7faec715ae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VZW0kllYahv",
        "outputId": "1f6c113c-09d4-41aa-fb15-8f1d7f9e53b6"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        " \n",
        "x_train = [1,2,3]\n",
        "y_train = [1,2,3]\n",
        "\n",
        "W = tf.Variable(tf.random.normal([1]), name = 'weight')\n",
        "b = tf.Variable(tf.random.normal([1]), name = 'bias')\n",
        "hypothesis = W*x_train+b\n",
        "\n",
        "@tf.function\n",
        "def cost():\n",
        "\n",
        "    y_model = W*x_train+b\n",
        "    error = tf.reduce_mean(tf.square(y_train- y_model))\n",
        "    return error\n",
        "\n",
        "\n",
        "optimizer = tf.optimizers.SGD (learning_rate=0.01)\n",
        "\n",
        "train = tf.keras.optimizers.Adam().minimize(cost, var_list=[W, b])\n",
        "\n",
        "tf.print(W)\n",
        "tf.print(b)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.674271047]\n",
            "[-1.00073934]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "awvUCccD3g0L"
      },
      "source": [
        "#loss\n",
        "J = []\n",
        "\n",
        "#scores\n",
        "scores = []\n",
        "\n",
        "#to store final parameters\n",
        "final_parameters = {}\n",
        "\n",
        "#number of episodes\n",
        "#M = 200001\n",
        "M = 200"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKwnEnAf3g0L"
      },
      "source": [
        "### Create training dataset and Train Simultaneously\n",
        "* Current Reward = number of merges + log(new max,2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmFa__UR3g0L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "53b7fff1-4e1d-4138-9ea8-2f5f75688cdd"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run()\n",
        "    print(\"Initialized\")\n",
        "    \n",
        "    global epsilon\n",
        "    global replay_labels\n",
        "    global replay_memory\n",
        "\n",
        "    #for episode with max score\n",
        "    maximum = -1\n",
        "    episode = -1\n",
        "    \n",
        "    #total_iters \n",
        "    total_iters = 1\n",
        "    \n",
        "    #number of back props\n",
        "    back=0\n",
        "    \n",
        "    for ep in range(M):\n",
        "        global board\n",
        "        board = new_game(4)\n",
        "        add_two(board)\n",
        "        add_two(board)\n",
        "        \n",
        "        #whether episode finished or not\n",
        "        finish = 'not over'\n",
        "        \n",
        "        #total_score of this episode\n",
        "        total_score = 0\n",
        "        \n",
        "        #iters per episode\n",
        "        local_iters = 1\n",
        "        \n",
        "        while(finish=='not over'):\n",
        "            prev_board = deepcopy(board)\n",
        "            \n",
        "            #get the required move for this state\n",
        "            state = deepcopy(board)\n",
        "            state = change_values(state)\n",
        "            state = np.array(state,dtype = np.float32).reshape(1,4,4,16)\n",
        "            feed_dict = {single_dataset:state}\n",
        "            control_scores = session.run(single_output,feed_dict=feed_dict)\n",
        "            \n",
        "            #find the move with max Q value\n",
        "            control_buttons = np.flip(np.argsort(control_scores),axis=1)\n",
        "            \n",
        "            #copy the Q-values as labels\n",
        "            labels = deepcopy(control_scores[0])\n",
        "            \n",
        "            #generate random number for epsilon greedy approach\n",
        "            num = random.uniform(0,1)\n",
        "            \n",
        "            #store prev max\n",
        "            prev_max = np.max(prev_board)\n",
        "            \n",
        "            #num is less epsilon generate random move\n",
        "            if(num<epsilon):\n",
        "                #find legal moves\n",
        "                legal_moves = list()\n",
        "                for i in range(4):\n",
        "                    temp_board = deepcopy(prev_board)\n",
        "                    temp_board,_,_ = controls[i](temp_board)\n",
        "                    if(np.array_equal(temp_board,prev_board)):\n",
        "                        continue\n",
        "                    else:\n",
        "                        legal_moves.append(i)\n",
        "                if(len(legal_moves)==0):\n",
        "                    finish = 'lose'\n",
        "                    continue\n",
        "                \n",
        "                #generate random move.\n",
        "                con = random.sample(legal_moves,1)[0]\n",
        "                \n",
        "                #apply the move\n",
        "                temp_state = deepcopy(prev_board)\n",
        "                temp_state,_,score = controls[con](temp_state)\n",
        "                total_score += score\n",
        "                finish = game_state(temp_state)\n",
        "                \n",
        "                #get number of merges\n",
        "                empty1 = findemptyCell(prev_board)\n",
        "                empty2 = findemptyCell(temp_state)\n",
        "                \n",
        "                if(finish=='not over'):\n",
        "                    temp_state = add_two(temp_state)\n",
        "\n",
        "                board = deepcopy(temp_state)\n",
        "\n",
        "                #get next max after applying the move\n",
        "                next_max = np.max(temp_state)\n",
        "                \n",
        "                #reward math.log(next_max,2)*0.1 if next_max is higher than prev max\n",
        "                labels[con] = (math.log(next_max,2))*0.1\n",
        "                \n",
        "                if(next_max==prev_max):\n",
        "                    labels[con] = 0\n",
        "                \n",
        "                #reward is also the number of merges\n",
        "                labels[con] += (empty2-empty1)\n",
        "                \n",
        "                #get the next state max Q-value\n",
        "                temp_state = change_values(temp_state)\n",
        "                temp_state = np.array(temp_state,dtype = np.float32).reshape(1,4,4,16)\n",
        "                feed_dict = {single_dataset:temp_state}\n",
        "                temp_scores = session.run(single_output,feed_dict=feed_dict)\n",
        "                    \n",
        "                max_qvalue = np.max(temp_scores)\n",
        "                \n",
        "                #final labels add gamma*max_qvalue\n",
        "                labels[con] = (labels[con] + gamma*max_qvalue)\n",
        "            \n",
        "            #generate the the max predicted move\n",
        "            else:\n",
        "                for con in control_buttons[0]:\n",
        "                    prev_state = deepcopy(prev_board)\n",
        "                    \n",
        "                    #apply the LEGAl Move with max q_value\n",
        "                    temp_state,_,score = controls[con](prev_state)\n",
        "                    \n",
        "                    #if illegal move label = 0\n",
        "                    if(np.array_equal(prev_board,temp_state)):\n",
        "                        labels[con] = 0\n",
        "                        continue\n",
        "                        \n",
        "                    #get number of merges\n",
        "                    empty1 = findemptyCell(prev_board)\n",
        "                    empty2 = findemptyCell(temp_state)\n",
        "\n",
        "                    \n",
        "                    temp_state = add_two(temp_state)\n",
        "                    board = deepcopy(temp_state)\n",
        "                    total_score += score\n",
        "\n",
        "                    next_max = np.max(temp_state)\n",
        "                    \n",
        "                    #reward\n",
        "                    labels[con] = (math.log(next_max,2))*0.1\n",
        "                    if(next_max==prev_max):\n",
        "                        labels[con] = 0\n",
        "                    \n",
        "                    labels[con] += (empty2-empty1)\n",
        "\n",
        "                    #get next max qvalue\n",
        "                    temp_state = change_values(temp_state)\n",
        "                    temp_state = np.array(temp_state,dtype = np.float32).reshape(1,4,4,16)\n",
        "                    feed_dict = {single_dataset:temp_state}\n",
        "                    temp_scores = session.run(single_output,feed_dict=feed_dict)\n",
        "\n",
        "                    max_qvalue = np.max(temp_scores)\n",
        "\n",
        "                    #final labels\n",
        "                    labels[con] = (labels[con] + gamma*max_qvalue)\n",
        "                    break\n",
        "                    \n",
        "                if(np.array_equal(prev_board,board)):\n",
        "                    finish = 'lose'\n",
        "            \n",
        "            #decrease the epsilon value\n",
        "            if((ep>10000) or (epsilon>0.1 and total_iters%2500==0)):\n",
        "                epsilon = epsilon/1.005\n",
        "                \n",
        "           \n",
        "            #change the matrix values and store them in memory\n",
        "            prev_state = deepcopy(prev_board)\n",
        "            prev_state = change_values(prev_state)\n",
        "            prev_state = np.array(prev_state,dtype=np.float32).reshape(1,4,4,16)\n",
        "            replay_labels.append(labels)\n",
        "            replay_memory.append(prev_state)\n",
        "            \n",
        "            \n",
        "            #back-propagation\n",
        "            if(len(replay_memory)>=mem_capacity):\n",
        "                back_loss = 0\n",
        "                batch_num = 0\n",
        "                z = list(zip(replay_memory,replay_labels))\n",
        "                np.random.shuffle(z)\n",
        "                np.random.shuffle(z)\n",
        "                replay_memory,replay_labels = zip(*z)\n",
        "                \n",
        "                for i in range(0,len(replay_memory),batch_size):\n",
        "                    if(i + batch_size>len(replay_memory)):\n",
        "                        break\n",
        "                        \n",
        "                    batch_data = deepcopy(replay_memory[i:i+batch_size])\n",
        "                    batch_labels = deepcopy(replay_labels[i:i+batch_size])\n",
        "                    \n",
        "                    batch_data = np.array(batch_data,dtype=np.float32).reshape(batch_size,4,4,16)\n",
        "                    batch_labels = np.array(batch_labels,dtype=np.float32).reshape(batch_size,output_units)\n",
        "                \n",
        "                    feed_dict = {tf_batch_dataset: batch_data, tf_batch_labels: batch_labels}\n",
        "                    _,l = session.run([optimizer,loss],feed_dict=feed_dict)\n",
        "                    back_loss += l \n",
        "                    \n",
        "                    print(\"Mini-Batch - {} Back-Prop : {}, Loss : {}\".format(batch_num,back,l))\n",
        "                    batch_num +=1\n",
        "                back_loss /= batch_num\n",
        "                J.append(back_loss)\n",
        "                \n",
        "                #store the parameters in a dictionary\n",
        "                final_parameters['conv1_layer1_weights'] = session.run(conv1_layer1_weights)\n",
        "                final_parameters['conv1_layer2_weights'] = session.run(conv1_layer2_weights)\n",
        "                final_parameters['conv2_layer1_weights'] = session.run(conv2_layer1_weights)\n",
        "                final_parameters['conv2_layer2_weights'] = session.run(conv2_layer2_weights)\n",
        "                final_parameters['conv1_layer1_biases'] = session.run(conv1_layer1_biases)\n",
        "                final_parameters['conv1_layer2_biases'] = session.run(conv1_layer2_biases)\n",
        "                final_parameters['conv2_layer1_biases'] = session.run(conv2_layer1_biases)\n",
        "                final_parameters['conv2_layer2_biases'] = session.run(conv2_layer2_biases)\n",
        "                final_parameters['fc_layer1_weights'] = session.run(fc_layer1_weights)\n",
        "                final_parameters['fc_layer2_weights'] = session.run(fc_layer2_weights)\n",
        "                final_parameters['fc_layer1_biases'] = session.run(fc_layer1_biases)\n",
        "                final_parameters['fc_layer2_biases'] = session.run(fc_layer2_biases)\n",
        "                \n",
        "                #number of back-props\n",
        "                back+=1\n",
        "                \n",
        "                #make new memory \n",
        "                replay_memory = list()\n",
        "                replay_labels = list()\n",
        "                \n",
        "            \n",
        "            if(local_iters%400==0):\n",
        "                print(\"Episode : {}, Score : {}, Iters : {}, Finish : {}\".format(ep,total_score,local_iters,finish))\n",
        "            \n",
        "            local_iters += 1\n",
        "            total_iters += 1\n",
        "            \n",
        "        scores.append(total_score)\n",
        "        print(\"Episode {} finished with score {}, result : {} board : {}, epsilon  : {}, learning rate : {} \".format(ep,total_score,finish,board,epsilon,session.run(learning_rate)))\n",
        "        print()\n",
        "        \n",
        "        if((ep+1)%1000==0):\n",
        "            print(\"Maximum Score : {} ,Episode : {}\".format(maximum,episode))    \n",
        "            print(\"Loss : {}\".format(J[len(J)-1]))\n",
        "            print()\n",
        "            \n",
        "        if(maximum<total_score):\n",
        "            maximum = total_score\n",
        "            episode = ep\n",
        "    print(\"Maximum Score : {} ,Episode : {}\".format(maximum,episode))    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Initialized\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1131\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1132\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3725\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3726\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3814\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" %\n\u001b[0;32m-> 3815\u001b[0;31m                       (type(obj).__name__, types_str))\n\u001b[0m\u001b[1;32m   3816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Can not convert a ResourceVariable into a Tensor.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c4d673ae1a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msingle_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mcontrol_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#find the move with max Q value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1132\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: ' +\n\u001b[0;32m-> 1134\u001b[0;31m                             e.args[0])\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Can not convert a ResourceVariable into a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duYTvpdT3g0M"
      },
      "source": [
        "### Store the Trained Weights in a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amJjzMg-3g0M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "d3afd5e9-3ca0-43ab-f8b6-78a0f3dc70e0"
      },
      "source": [
        "path = r'E:\\Study n Work\\Projects\\2048\\Final Weights'\n",
        "weights = ['conv1_layer1_weights','conv1_layer2_weights','conv2_layer1_weights','conv2_layer2_weights','fc_layer1_weights','fc_layer1_biases','fc_layer2_weights','fc_layer2_biases']\n",
        "for w in weights:\n",
        "    flatten = final_parameters[w].reshape(-1,1)\n",
        "    file = open(path + '\\\\' + w +'.csv','w')\n",
        "    file.write('Sno,Weight\\n')\n",
        "    for i in range(flatten.shape[0]):\n",
        "        file.write(str(i) +',' +str(flatten[i][0])+'\\n') \n",
        "    file.close()\n",
        "    print(w + \" written!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e5671c93d5cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_layer1_weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'conv1_layer2_weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'conv2_layer1_weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'conv2_layer2_weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fc_layer1_weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fc_layer1_biases'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fc_layer2_weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fc_layer2_biases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\\\'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sno,Weight\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conv1_layer1_weights'"
          ]
        }
      ]
    }
  ]
}